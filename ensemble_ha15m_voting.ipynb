{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "784f06ce",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd6b132f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print('Libraries loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf9a219",
   "metadata": {},
   "source": [
    "## 2. Load Individual Model Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10825d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM shape: (95763, 2)\n",
      "Random Forest shape: (95763, 2)\n",
      "XGBoost shape: (78382, 2)\n",
      "\n",
      "LSTM columns: ['Time', 'LSTM_Prediction']\n",
      "RF columns: ['Time', 'RF_Prediction']\n",
      "XGB columns: ['Time', 'XGB_Prediction']\n"
     ]
    }
   ],
   "source": [
    "# Load forecasts from all three models\n",
    "lstm_forecast = pd.read_csv('lstm_ha15m_forecast.csv')\n",
    "rf_forecast = pd.read_csv('randomforest_ha15m_forecast.csv')\n",
    "xgb_forecast = pd.read_csv('xgboost_ha15m_forecast.csv')\n",
    "\n",
    "print(f'LSTM shape: {lstm_forecast.shape}')\n",
    "print(f'Random Forest shape: {rf_forecast.shape}')\n",
    "print(f'XGBoost shape: {xgb_forecast.shape}')\n",
    "\n",
    "print(f'\\nLSTM columns: {lstm_forecast.columns.tolist()}')\n",
    "print(f'RF columns: {rf_forecast.columns.tolist()}')\n",
    "print(f'XGB columns: {xgb_forecast.columns.tolist()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2640adc5",
   "metadata": {},
   "source": [
    "## 3. Merge Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "458ba57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble dataframe shape: (95763, 4)\n",
      "\n",
      "First 10 rows:\n",
      "                  Time  LSTM_Pred  RF_Pred  XGB_Pred\n",
      "0  2023-01-01 00:00:00        0.0       -1      -1.0\n",
      "1  2023-01-01 00:15:00        0.0       -1      -1.0\n",
      "2  2023-01-01 00:30:00        0.0       -1       1.0\n",
      "3  2023-01-01 00:45:00        0.0        1       1.0\n",
      "4  2023-01-01 01:00:00        0.0        1      -1.0\n",
      "5  2023-01-01 01:15:00       -1.0       -1       1.0\n",
      "6  2023-01-01 01:30:00       -1.0       -1       1.0\n",
      "7  2023-01-01 01:45:00        1.0        1      -1.0\n",
      "8  2023-01-01 02:00:00       -1.0        1       1.0\n",
      "9  2023-01-01 02:15:00       -1.0       -1       1.0\n"
     ]
    }
   ],
   "source": [
    "# Merge all forecasts\n",
    "ensemble_df = pd.DataFrame()\n",
    "ensemble_df['Time'] = lstm_forecast['Time']\n",
    "ensemble_df['LSTM_Pred'] = lstm_forecast.iloc[:, 1]  # Second column\n",
    "ensemble_df['RF_Pred'] = rf_forecast.iloc[:, 1]\n",
    "ensemble_df['XGB_Pred'] = xgb_forecast.iloc[:, 1]\n",
    "\n",
    "print(f'Ensemble dataframe shape: {ensemble_df.shape}')\n",
    "print(f'\\nFirst 10 rows:')\n",
    "print(ensemble_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1b2a82",
   "metadata": {},
   "source": [
    "## 4. Majority Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "229b2a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble voting complete!\n",
      "\n",
      "Vote distribution:\n",
      "Ensemble_Vote\n",
      " 1    47938\n",
      "-1    40508\n",
      " 0     7317\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Ensemble voting logic:\n",
    "# 2+ models predict 1 → signal = 1 (BULLISH)\n",
    "# 2+ models predict -1 → signal = -1 (BEARISH)\n",
    "# Split decision (1 votes each) → signal = 0 (NEUTRAL)\n",
    "\n",
    "def ensemble_vote(lstm, rf, xgb):\n",
    "    votes = [lstm, rf, xgb]\n",
    "    bullish = sum(1 for v in votes if v == 1)\n",
    "    bearish = sum(1 for v in votes if v == -1)\n",
    "    \n",
    "    if bullish >= 2:\n",
    "        return 1  # Consensus BULLISH\n",
    "    elif bearish >= 2:\n",
    "        return -1  # Consensus BEARISH\n",
    "    else:\n",
    "        return 0  # No consensus\n",
    "\n",
    "ensemble_df['Ensemble_Vote'] = ensemble_df.apply(\n",
    "    lambda row: ensemble_vote(row['LSTM_Pred'], row['RF_Pred'], row['XGB_Pred']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print('Ensemble voting complete!')\n",
    "print(f'\\nVote distribution:')\n",
    "print(ensemble_df['Ensemble_Vote'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d332f8b",
   "metadata": {},
   "source": [
    "## 5. Calculate Agreement Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ab1c099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agreement metrics calculated\n",
      "\n",
      "Agreement distribution:\n",
      "Agreement_Count\n",
      "0     7317\n",
      "1    66726\n",
      "3    21720\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count how many models agree\n",
    "def count_agreement(lstm, rf, xgb):\n",
    "    votes = [lstm, rf, xgb]\n",
    "    agreement_count = 0\n",
    "    \n",
    "    # Count matching predictions\n",
    "    if lstm == rf:\n",
    "        agreement_count += 1\n",
    "    if lstm == xgb:\n",
    "        agreement_count += 1\n",
    "    if rf == xgb:\n",
    "        agreement_count += 1\n",
    "    \n",
    "    return agreement_count  # 0 to 3\n",
    "\n",
    "ensemble_df['Agreement_Count'] = ensemble_df.apply(\n",
    "    lambda row: count_agreement(row['LSTM_Pred'], row['RF_Pred'], row['XGB_Pred']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Agreement percentage\n",
    "ensemble_df['Consensus_Strength'] = (ensemble_df['Agreement_Count'] / 3) * 100\n",
    "\n",
    "print('Agreement metrics calculated')\n",
    "print(f'\\nAgreement distribution:')\n",
    "print(ensemble_df['Agreement_Count'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f545f9",
   "metadata": {},
   "source": [
    "## 6. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d0e5e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Voting Results:\n",
      "  Bullish signals: 47938 (50.1%)\n",
      "  Bearish signals: 40508 (42.3%)\n",
      "  Neutral signals: 7317 (7.6%)\n",
      "Average Consensus Strength: 45.9%\n",
      "  Strong consensus (100%): 21720\n",
      "  Moderate consensus (67%): 0\n",
      "  Weak consensus (33%): 0\n"
     ]
    }
   ],
   "source": [
    "bullish_signals = (ensemble_df['Ensemble_Vote'] == 1).sum()\n",
    "bearish_signals = (ensemble_df['Ensemble_Vote'] == -1).sum()\n",
    "neutral_signals = (ensemble_df['Ensemble_Vote'] == 0).sum()\n",
    "\n",
    "print(f\"Ensemble Voting Results:\")\n",
    "print(f\"  Bullish signals: {bullish_signals} ({bullish_signals/len(ensemble_df)*100:.1f}%)\")\n",
    "print(f\"  Bearish signals: {bearish_signals} ({bearish_signals/len(ensemble_df)*100:.1f}%)\")\n",
    "print(f\"  Neutral signals: {neutral_signals} ({neutral_signals/len(ensemble_df)*100:.1f}%)\")\n",
    "\n",
    "avg_consensus = ensemble_df['Consensus_Strength'].mean()\n",
    "print(f\"Average Consensus Strength: {avg_consensus:.1f}%\")\n",
    "print(f\"  Strong consensus (100%): {(ensemble_df['Consensus_Strength'] == 100).sum()}\")\n",
    "print(f\"  Moderate consensus (67%): {(ensemble_df['Consensus_Strength'] == 66.67).sum()}\")\n",
    "print(f\"  Weak consensus (33%): {(ensemble_df['Consensus_Strength'] == 33.33).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66921e4a",
   "metadata": {},
   "source": [
    "## 7. Confidence Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0111bba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence scores calculated\n",
      "Average confidence: 71.68%\n"
     ]
    }
   ],
   "source": [
    "# Confidence = percentage of models agreeing with majority\n",
    "def calculate_confidence(lstm, rf, xgb, vote):\n",
    "    if vote == 0:  # Neutral\n",
    "        return 33.33  # Lowest confidence\n",
    "    \n",
    "    agreeing = 0\n",
    "    if lstm == vote:\n",
    "        agreeing += 1\n",
    "    if rf == vote:\n",
    "        agreeing += 1\n",
    "    if xgb == vote:\n",
    "        agreeing += 1\n",
    "    \n",
    "    return (agreeing / 3) * 100\n",
    "\n",
    "ensemble_df['Confidence'] = ensemble_df.apply(\n",
    "    lambda row: calculate_confidence(\n",
    "        row['LSTM_Pred'], row['RF_Pred'], row['XGB_Pred'], row['Ensemble_Vote']\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print('Confidence scores calculated')\n",
    "print(f\"Average confidence: {ensemble_df['Confidence'].mean():.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473717be",
   "metadata": {},
   "source": [
    "## 8. Save Ensemble Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d013bcfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble forecast saved: ensemble_ha15m_forecast.csv\n",
      "Shape: (95763, 6)\n",
      "\n",
      "First 10 rows:\n",
      "                  Time  LSTM  RandomForest  XGBoost  Ensemble  Confidence\n",
      "0  2023-01-01 00:00:00   0.0            -1     -1.0        -1   66.666667\n",
      "1  2023-01-01 00:15:00   0.0            -1     -1.0        -1   66.666667\n",
      "2  2023-01-01 00:30:00   0.0            -1      1.0         0   33.330000\n",
      "3  2023-01-01 00:45:00   0.0             1      1.0         1   66.666667\n",
      "4  2023-01-01 01:00:00   0.0             1     -1.0         0   33.330000\n",
      "5  2023-01-01 01:15:00  -1.0            -1      1.0        -1   66.666667\n",
      "6  2023-01-01 01:30:00  -1.0            -1      1.0        -1   66.666667\n",
      "7  2023-01-01 01:45:00   1.0             1     -1.0         1   66.666667\n",
      "8  2023-01-01 02:00:00  -1.0             1      1.0         1   66.666667\n",
      "9  2023-01-01 02:15:00  -1.0            -1      1.0        -1   66.666667\n"
     ]
    }
   ],
   "source": [
    "# Create output CSV with essential columns\n",
    "output_df = ensemble_df[['Time', 'LSTM_Pred', 'RF_Pred', 'XGB_Pred', 'Ensemble_Vote', 'Confidence']].copy()\n",
    "\n",
    "# Rename for clarity\n",
    "output_df.columns = ['Time', 'LSTM', 'RandomForest', 'XGBoost', 'Ensemble', 'Confidence']\n",
    "\n",
    "output_df.to_csv('ensemble_ha15m_forecast.csv', index=False)\n",
    "\n",
    "print('Ensemble forecast saved: ensemble_ha15m_forecast.csv')\n",
    "print(f'Shape: {output_df.shape}')\n",
    "print(f'\\nFirst 10 rows:')\n",
    "print(output_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7505db74",
   "metadata": {},
   "source": [
    "## 9. Model Agreement Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba313c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check pairwise agreement between models\n",
    "lstm_rf_agree = (ensemble_df['LSTM_Pred'] == ensemble_df['RF_Pred']).sum()\n",
    "lstm_xgb_agree = (ensemble_df['LSTM_Pred'] == ensemble_df['XGB_Pred']).sum()\n",
    "rf_xgb_agree = (ensemble_df['RF_Pred'] == ensemble_df['XGB_Pred']).sum()\n",
    "\n",
    "total = len(ensemble_df)\n",
    "\n",
    "print('Pairwise Agreement:')\n",
    "print(f'  LSTM ↔ RF:   {lstm_rf_agree}/{total} ({lstm_rf_agree/total*100:.1f}%)')\n",
    "print(f'  LSTM ↔ XGB:  {lstm_xgb_agree}/{total} ({lstm_xgb_agree/total*100:.1f}%)')\n",
    "print(f'  RF ↔ XGB:    {rf_xgb_agree}/{total} ({rf_xgb_agree/total*100:.1f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e1db3b",
   "metadata": {},
   "source": [
    "## 10. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0db1281",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*60)\n",
    "print('ENSEMBLE VOTING SUMMARY')\n",
    "print('='*60)\n",
    "print(f\"\\nTotal Bars: {len(ensemble_df)}\")\n",
    "print(f\"\\nSignal Distribution:\")\n",
    "print(f\"  Bullish (1):   {bullish_signals:6d} ({bullish_signals/total*100:5.1f}%)\")\n",
    "print(f\"  Bearish (-1):  {bearish_signals:6d} ({bearish_signals/total*100:5.1f}%)\")\n",
    "print(f\"  Neutral (0):   {neutral_signals:6d} ({neutral_signals/total*100:5.1f}%)\")\n",
    "print(f\"\\nConsensus Metrics:\")\n",
    "print(f\"  Average Consensus: {avg_consensus:.1f}%\")\n",
    "print(f\"  Average Confidence: {ensemble_df['Confidence'].mean():.1f}%\")\n",
    "print(f\"\\nModel Agreement:\")\n",
    "print(f\"  LSTM ↔ RF:   {lstm_rf_agree/total*100:.1f}%\")\n",
    "print(f\"  LSTM ↔ XGB:  {lstm_xgb_agree/total*100:.1f}%\")\n",
    "print(f\"  RF ↔ XGB:    {rf_xgb_agree/total*100:.1f}%\")\n",
    "print(f\"\\nOutput File: ensemble_ha15m_forecast.csv\")\n",
    "print('='*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
